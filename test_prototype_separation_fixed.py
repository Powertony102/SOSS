#!/usr/bin/env python3
"""
å®Œå…¨ä¿®å¤çš„åŸå‹åˆ†ç¦»æ¨¡å—æµ‹è¯•ä»£ç 
è§£å†³äº†æ‰€æœ‰autogradå›¾äº¤å‰å¼•ç”¨é—®é¢˜
"""

import torch
import numpy as np
from myutils.prototype_separation import PrototypeMemory


def create_independent_test_data(batch_size, feat_dim, num_classes, H, W, D, device, seed):
    """åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„æµ‹è¯•æ•°æ®ï¼Œé¿å…autogradå›¾äº¤å‰å¼•ç”¨"""
    torch.manual_seed(seed)
    
    # åˆ›å»ºç‹¬ç«‹çš„å¼ é‡
    feat = torch.randn(batch_size, feat_dim, H, W, D, device=device, requires_grad=True)
    logits = torch.randn(batch_size, num_classes + 1, H, W, D, device=device)
    pred = torch.softmax(logits, dim=1)
    label = torch.randint(0, num_classes + 1, (batch_size, 1, H, W, D), device=device)
    is_labelled = torch.tensor([True, True, False, False], device=device)
    
    return feat, pred, label, is_labelled


def test_single_forward_backward():
    """æµ‹è¯•å•æ¬¡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­"""
    print("="*60)
    print("æµ‹è¯•å•æ¬¡å‰å‘å’Œåå‘ä¼ æ’­")
    print("="*60)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºåŸå‹å†…å­˜æ¨¡å—
    proto_mem = PrototypeMemory(
        num_classes=2,
        feat_dim=64,
        proto_momentum=0.9,
        conf_thresh=0.8,
        lambda_intra=0.5,
        lambda_inter=0.1,
        margin_m=1.0,
        device=device
    ).to(device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    feat, pred, label, is_labelled = create_independent_test_data(
        batch_size=2, feat_dim=64, num_classes=2, H=32, W=32, D=16, device=device, seed=42
    )
    
    print(f"è¾“å…¥å¼ é‡å½¢çŠ¶:")
    print(f"  feat: {feat.shape}")
    print(f"  pred: {pred.shape}")
    print(f"  label: {label.shape}")
    print(f"  is_labelled: {is_labelled.shape}")
    
    # å‰å‘ä¼ æ’­
    loss_dict = proto_mem(feat, label, pred, is_labelled, epoch_idx=0)
    
    # å®‰å…¨æå–æŸå¤±å€¼
    intra_loss = loss_dict['intra'].detach().item()
    inter_loss = loss_dict['inter'].detach().item()
    total_loss = loss_dict['total'].detach().item()
    n_confident = int(loss_dict['n_confident_pixels'])
    n_protos = int(loss_dict['n_initialized_protos'])
    
    print(f"\næŸå¤±è®¡ç®—ç»“æœ:")
    print(f"  ç±»å†…æŸå¤±: {intra_loss:.4f}")
    print(f"  ç±»é—´æŸå¤±: {inter_loss:.4f}")
    print(f"  æ€»æŸå¤±: {total_loss:.4f}")
    print(f"  é«˜ç½®ä¿¡åº¦åƒç´ : {n_confident}")
    print(f"  å·²åˆå§‹åŒ–åŸå‹: {n_protos}")
    
    # åå‘ä¼ æ’­
    print(f"\næ‰§è¡Œåå‘ä¼ æ’­...")
    loss_dict['total'].backward()
    print(f"âœ“ åå‘ä¼ æ’­æˆåŠŸ")
    print(f"  featæ¢¯åº¦å­˜åœ¨: {feat.grad is not None}")
    if feat.grad is not None:
        print(f"  featæ¢¯åº¦èŒƒæ•°: {feat.grad.norm().detach().item():.6f}")
    
    print("âœ“ å•æ¬¡å‰å‘åå‘ä¼ æ’­æµ‹è¯•é€šè¿‡")


def test_multi_epoch_training():
    """æµ‹è¯•å¤šepochè®­ç»ƒå¾ªç¯ï¼Œå®Œå…¨è§£å†³æ¢¯åº¦å›¾äº¤å‰å¼•ç”¨é—®é¢˜"""
    print("\n" + "="*60)
    print("æµ‹è¯•å¤šepochè®­ç»ƒå¾ªç¯ï¼ˆå®Œå…¨éš”ç¦»ç‰ˆæœ¬ï¼‰")
    print("="*60)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # åˆ›å»ºåŸå‹å†…å­˜æ¨¡å—
    proto_mem = PrototypeMemory(
        num_classes=2,
        feat_dim=128,
        proto_momentum=0.9,
        conf_thresh=0.8,
        lambda_intra=0.5,
        lambda_inter=0.1,
        margin_m=1.0,
        device=device
    ).to(device)
    
    print(f"åˆå§‹åŒ–PrototypeMemory: 2ç±»ï¼Œè®¾å¤‡={device}")
    
    batch_size = 4
    H, W, D = 64, 64, 32
    
    for epoch in range(3):
        print(f"\nEpoch {epoch + 1}:")
        
        # **é˜¶æ®µ1**: åŸå‹æ›´æ–° - ä½¿ç”¨ç‹¬ç«‹æ•°æ® + no_grad
        with torch.no_grad():
            update_feat, update_pred, update_label, update_is_labelled = create_independent_test_data(
                batch_size=batch_size, feat_dim=128, num_classes=2, 
                H=H, W=W, D=D, device=device, seed=1000 + epoch
            )
            
            # ç§»é™¤requires_gradï¼Œå› ä¸ºåœ¨no_gradä¸­
            update_feat = update_feat.detach()
            
            # ä»…æ›´æ–°åŸå‹
            _ = proto_mem(update_feat, update_label, update_pred, update_is_labelled, epoch_idx=epoch)
            
            # ç«‹å³æ¸…ç†
            del update_feat, update_pred, update_label, update_is_labelled
        
        # **é˜¶æ®µ2**: æŸå¤±è®¡ç®— - ä½¿ç”¨å®Œå…¨ä¸åŒçš„æ•°æ®
        loss_feat, loss_pred, loss_label, loss_is_labelled = create_independent_test_data(
            batch_size=batch_size, feat_dim=128, num_classes=2,
            H=H, W=W, D=D, device=device, seed=2000 + epoch
        )
        
        # è®¡ç®—æŸå¤±ï¼ˆä¸æ›´æ–°åŸå‹ï¼‰
        proto_losses = proto_mem(loss_feat, loss_label, loss_pred, loss_is_labelled, epoch_idx=None)
        
        # **é˜¶æ®µ3**: å®‰å…¨æå–æŸå¤±å€¼
        intra_val = proto_losses['intra'].detach().item()
        inter_val = proto_losses['inter'].detach().item()
        total_proto_val = proto_losses['total'].detach().item()
        n_confident = int(proto_losses['n_confident_pixels'])
        n_protos = int(proto_losses['n_initialized_protos'])
        
        print(f"  ç±»å†…æŸå¤±: {intra_val:.4f}")
        print(f"  ç±»é—´æŸå¤±: {inter_val:.4f}")
        print(f"  åŸå‹æ€»æŸå¤±: {total_proto_val:.4f}")
        print(f"  é«˜ç½®ä¿¡åº¦åƒç´ : {n_confident}")
        print(f"  å·²åˆå§‹åŒ–åŸå‹: {n_protos}")
        
        # **é˜¶æ®µ4**: åˆ›å»ºå…¶ä»–æŸå¤±å¹¶ç»„åˆ
        other_loss1 = torch.randn(1, device=device, requires_grad=True) * 0.1
        other_loss2 = torch.randn(1, device=device, requires_grad=True) * 0.1
        
        total_loss = other_loss1 + other_loss2 + 0.5 * proto_losses['total']
        total_val = total_loss.detach().item()
        print(f"  æ€»æŸå¤±: {total_val:.4f}")
        
        # **é˜¶æ®µ5**: åå‘ä¼ æ’­
        total_loss.backward()
        print(f"  âœ“ æ¢¯åº¦è®¡ç®—æˆåŠŸ")
        
        # **é˜¶æ®µ6**: å½»åº•æ¸…ç†
        del total_loss, proto_losses, other_loss1, other_loss2
        del loss_feat, loss_pred, loss_label, loss_is_labelled
        
        # GPUå†…å­˜æ¸…ç†
        if device == 'cuda':
            torch.cuda.empty_cache()
    
    print("\nâœ“ å¤šepochè®­ç»ƒæµ‹è¯•å®Œå…¨æˆåŠŸï¼")


def test_prototype_statistics():
    """æµ‹è¯•åŸå‹ç»Ÿè®¡åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯•åŸå‹ç»Ÿè®¡åŠŸèƒ½")
    print("="*60)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    proto_mem = PrototypeMemory(
        num_classes=3,
        feat_dim=64,
        device=device
    ).to(device)
    
    # åˆå§‹åŒ–ä¸€äº›åŸå‹
    for epoch in range(2):
        with torch.no_grad():
            feat, pred, label, is_labelled = create_independent_test_data(
                batch_size=2, feat_dim=64, num_classes=3,
                H=32, W=32, D=16, device=device, seed=500 + epoch
            )
            feat = feat.detach()  # ç§»é™¤æ¢¯åº¦
            _ = proto_mem(feat, label, pred, is_labelled, epoch_idx=epoch)
            del feat, pred, label, is_labelled
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    with torch.no_grad():
        stats = proto_mem.get_prototype_statistics()
        
        print(f"åŸå‹ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  å·²åˆå§‹åŒ–åŸå‹æ•°: {stats['num_initialized']}")
        print(f"  æ€»ç±»åˆ«æ•°: {stats['total_classes']}")
        print(f"  æœ€åæ›´æ–°epoch: {stats['last_update_epoch']}")
        
        if 'mean_prototype_norm' in stats:
            print(f"  å¹³å‡åŸå‹èŒƒæ•°: {stats['mean_prototype_norm']:.4f}")
        
        if 'mean_pairwise_distance' in stats:
            print(f"  å¹³å‡åŸå‹é—´è·ç¦»: {stats['mean_pairwise_distance']:.4f}")
    
    print("âœ“ åŸå‹ç»Ÿè®¡æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    try:
        test_single_forward_backward()
        test_multi_epoch_training()
        test_prototype_statistics()
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œå…¨é€šè¿‡ï¼æ¢¯åº¦é—®é¢˜å·²å½»åº•è§£å†³ï¼")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc() 