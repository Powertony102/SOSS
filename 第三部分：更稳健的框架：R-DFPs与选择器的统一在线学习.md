## 第三部分：更稳健的框架：R-DFPs与选择器的统一在线学习



为了克服上述缺陷，我们提出一个全新的、统一的在线学习框架。该框架摒弃了僵化的分阶段调度，转而采用一种受在线深度聚类（ODC）、动量更新（momentum update） 和迭代式伪标签  启发的整合方案。  



### 3.1 核心原则：联合、在线与迭代优化



我们的核心理念是**“并肩演化”（shoulder-to-shoulder）**。R-DFPs（由其中心向量表示）、选择器模块和主分割网络不再交替进行，而是在每个训练迭代中同时、连续地演化，通过每一个小批量数据相互优化。这种方法已被证明能显著提升训练的稳定性、计算效率，并与最前沿的自监督学习范式保持一致 。  





### 3.2 架构组件设计





#### 3.2.1 区域特异性动态特征池（R-DFPs）



- `num_dfp`个R-DFP中的每一个都由一个**中心向量（centroid vector）** ck∈RD 来表示，其中 D 是特征嵌入的维度。
- 这些中心向量不是静态的锚点，而是**动态演化的原型（dynamic prototypes）**，在训练过程中不断被更新。
- 为提高计算效率，我们主要操作中心向量，而不是维护一个包含所有分配给该簇的特征的显式内存池。



#### 3.2.2 特征池选择器（Feature Pool Selector, FPS）模块



- **功能**：FPS模块，记为 S(⋅)，接收来自编码器投影头的特征向量 z 作为输入，并输出一个覆盖 `num_dfp` 个池的概率分布：$S(z) = [p_1, p_2, \dots, p_{\text{num\_dfp}}]$ 其中 $\sum_{k} p_k = 1$

- **架构**：一个轻量级的多层感知机（Multi-Layer Perceptron, MLP）是实现FPS的理想选择 。为了增强其表达能力，我们推荐引入门控机制。  

  

  - **基线方案**：一个包含2-3个全连接层、ReLU激活函数和最终Softmax层的标准MLP。
  - **推荐方案**：一个基于门控线性单元（Gated Linear Unit, GLU）的门控MLP（Gated MLP）。gMLP中的空间门控单元（Spatial Gating Unit, SGU）展示了简单的MLP如何学习复杂的特征交互 。我们可以借鉴此思想，在选择器中使用GLU结构。这使得选择器不仅能“选择”路径，还能“调制”信息流，成为一种更灵活的“软路由”（soft routing）功能 



### 3.3 统一在线训练算法

我们提出的训练流程分为两个主要阶段：一个简短的预热阶段和一个持续的在线联合学习阶段。

#### 3.3.1 阶段一：预热（例如，`iter < dfp_start_iter`）
在此阶段，我们仅使用CORN的标准损失函数 $ L_s + \lambda_c \cdot l_c $ 来训练双编码器网络。这一步至关重要，它能确保编码器在进入联合学习阶段前，已经能够产出具有一定语义信息和可分性的特征。

#### 3.3.2 阶段二：在线联合学习（例如，`iter >= dfp_start_iter`）

- **初始化（仅在 `dfp_start_iter` 时执行一次）**：
    - 将一个较大且有代表性的数据集（如部分训练集）通过预热好的主编码器，以获取一批初始特征向量。
    - 在这些特征向量上运行 `k - means++` 算法，以初始化 `num_dfp` 个R - DFP的中心向量 $ \{ c_k \} $。相比随机初始化，`k - means++` 能提供更好的初始中心点分布，避免陷入糟糕的局部最优。

- **迭代循环（此后每个小批量 `B` 都执行）**：
    - **a. 特征提取**：对于批次中的每个样本 $ x_i $，从主编码器的投影头提取其特征嵌入 $ z_i $。
    - **b. 伪标签分配（硬分配）**：对于每个特征 $ z_i $，计算其与所有中心向量 $ \{ c_k \} $ 的余弦相似度，并将其分配给最相似的中心。这个分配结果 $ y_i $ 将作为训练选择器的“基准”伪标签。
    - $$ y_i = \arg \max_k (\text{CORAL\_similarity}(z_i, c_k)) $$
    - **c. 选择器训练**：训练FPS模块 $ S(\cdot) $ 来预测这些伪标签。
        $$ L_{\text{selector}} = \text{CrossEntropy}(S(z_i), y_i), \forall i \in B $$
    - **d. 表示与分割学习**：
        - 计算标准的监督损失和交叉伪监督损失。
        - 关键创新在于，将一致性损失 $ l_d $ 改造为R - DFP特异性的。我们使用选择器的软输出 $ p_i = S(z_i) $ 作为权重，来计算每个样本对其所属簇的一致性损失的贡献。
        $$ L_{\text{consistency}} = \sum_{i \in B} \sum_{k = 1}^{\text{num\_dfp}} p_{i,k} \cdot l_d(z_i, c_k) $$
        其中 $ l_d(z_i, c_k) $ 是特征 $ z_i $ 与其对应的中心 $ c_k $ 之间的CORAL损失。
    - **e. R - DFP中心动量更新**：使用动量移动平均（momentum - based moving average）来更新每个中心 $ c_k $。这是从MoCo、Mean Teacher等成功的自监督学习方法中借鉴的核心思想，可确保中心向量平滑、稳定地演化。
        - 对于每个中心 $ c_k $，找出当前批次中所有被分配给它的特征集合 $ \{ z_j \} $（即 $ y_j = k $）。
        - $$ c_k \leftarrow m \cdot c_k + (1 - m) \cdot \text{mean}(\{ z_j \}) $$
        其中 $ m $ 是动量系数（例如，$ 0.999 $）。
    - **f. 反向传播**：计算总损失并更新网络参数（编码器、投影头、选择器）。
        $$ L_{\text{total}} = L_s + \lambda_c l_c + \lambda_d L_{\text{consistency}} + \lambda_{\text{sel}} L_{\text{selector}} $$
        - **梯度流控制**：一个关键的实现细节是，来自选择器损失 $ L_{\text{selector}} $ 的梯度不应回传到主编码器。选择器的任务是学习已存在的簇结构，而不是影响该结构的形成。相反，来自一致性损失 $ L_{\text{consistency}} $ 的梯度则需要回传到编码器，以驱动特征向其所属的簇中心靠拢。在每个批次中，中心向量 $ \{ c_k \} $ 被视为非可微的目标，仅通过动量规则进行更新。

